{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76624639-8ca7-4724-a06b-3685e97ec55c",
   "metadata": {},
   "source": [
    "# Notebook for statistical analysis of model training and performance eval\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f196a8-fdb8-47d8-8b56-5cdbae1c5f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from agents import MinimaxAgent, RandomAgent, AvoidNextLossAgent, ModelAgent, NeuroevolutionAgent\n",
    "from environment import ConnectFourEnv\n",
    "from evaluation_func import EvaluationFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69013a6-5aa8-4ecf-9678-da0bbf13d138",
   "metadata": {},
   "source": [
    "## Training performance evaluation\n",
    "The goal is to visualize the training performance of each model in a graph regarding loss and average return since those metrics were collected.\n",
    "### Preparing the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddce01a-3259-4489-aa69-ce317d33ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the initial dictionary by grid and loading the train data\n",
    "dfs = {}\n",
    "train_data = pd.read_csv('./training_data.csv',index_col=None)\n",
    "\n",
    "#splitting the training data by model training data\n",
    "dfs['6by7'] = train_data[train_data['PATH'] == './weights/d6by7.h5']\n",
    "dfs['8by9'] = train_data[train_data['PATH'] == './weights/d8by9.h5']\n",
    "dfs['10by11'] = train_data[train_data['PATH'] == './weights/d10by11.h5']\n",
    "dfs['12by13'] = train_data[train_data['PATH'] == './weights/d12by13.h5']\n",
    "\n",
    "#making the epoch the index for each dataframe\n",
    "dfs['6by7'].set_index('EPOCH')\n",
    "dfs['8by9'].set_index('EPOCH')\n",
    "dfs['10by11'].set_index('EPOCH')\n",
    "dfs['12by13'].set_index('EPOCH')\n",
    "\n",
    "dfs['6by7'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc0829b-7769-4194-977a-260e7d56b657",
   "metadata": {},
   "source": [
    "### Visualization functions\n",
    "We write a basic function for visualizing training process in matplotlib and save the figure at a desired path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4235b3-1e43-4350-a076-ad7496213a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_progress(df, name : str, col_val : str, path : str, show=False):\n",
    "    '''\n",
    "    Function to show and also save a graph containing the reward over all episodes.\n",
    "    :param epoch_returns (list): A list of acerage returns for n epochs (defined as 1000 training steps).\n",
    "    '''\n",
    "\n",
    "    x = np.arange(0, len())\n",
    "    y = df[col_val].numpy()\n",
    "\n",
    "    plt.style.use('dark_background')\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x,y)\n",
    "\n",
    "    ax.set_title(f'Training progress for model {name}')\n",
    "    ax.set_ylabel(f' {col_val} per epoch')\n",
    "    ax.set_xlabel('Epochs')\n",
    "\n",
    "    fig.savefig(path)\n",
    "    \n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb78a94-971a-4059-84c1-9a36029fcd88",
   "metadata": {},
   "source": [
    "We then run the function for each model we trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7340f8-5f14-46d7-8d59-267b27d60a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_progress(dfs['6by7'], 'DQN-6x7', 'AVERAGE LOSS', './figures/6by7avgloss.png')\n",
    "visualize_progress(dfs['6by7'], 'DQN-6x7', 'AVERAGE RETURN', './figures/6by7avgret.png')\n",
    "\n",
    "visualize_progress(dfs['8by9'], 'DQN-8x9', 'AVERAGE LOSS', './figures/8by9avgloss.png')\n",
    "visualize_progress(dfs['8by9'], 'DQN-8x9', 'AVERAGE RETURN', './figures/8by9avgret.png')\n",
    "\n",
    "visualize_progress(dfs['10by11'], 'DQN-10x11', 'AVERAGE LOSS', './figures/10by11avgloss.png')\n",
    "visualize_progress(dfs['10by11'], 'DQN-10x11', 'AVERAGE RETURN', './figures/10by11avgret.png')\n",
    "\n",
    "visualize_progress(dfs['12by13'], 'DQN-12x13', 'AVERAGE LOSS', './figures/12by13avgloss.png')\n",
    "visualize_progress(dfs['12by13'], 'DQN-12x13', 'AVERAGE RETURN', './figures/12by13avgret.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62e13ad-376f-4dd9-8b81-c7567b892036",
   "metadata": {},
   "source": [
    "## Agent performance evaluation\n",
    "Our goal is to evaluate the performance of each model against each other per grid size of the Environment.\n",
    "If there is a significant advantage of one model over another based on statistics it can be called better.\n",
    "\n",
    "### Agent initialization\n",
    "We firstly initialize every agent we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b5c5cf-511c-4f03-a5e7-2dcc8dd40d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimax = MinimaxAgent()\n",
    "random = RandomAgent()\n",
    "lossavoid = AvoidNextLossAgent()\n",
    "\n",
    "dqn = {}\n",
    "dqn['6by7'] = ModelAgent('d6by7')\n",
    "dqn['8by9'] = ModelAgent('d8by9')\n",
    "dqn['10by11'] = ModelAgent('d10by11')\n",
    "dqn['12by13'] = ModelAgent('d12by13')\n",
    "\n",
    "neuroevo = NeuroevolutionAgent('Evolved_ANN.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f502a3-e978-4fc2-ac25-a3dcc1e347bb",
   "metadata": {},
   "source": [
    "### Evaluation function initialization\n",
    "We also initialize the evaluation function with parameters which we want to use for minimax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a312c4-7de5-447d-8439-e8cfa27bac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = None #TODO\n",
    "eval_func = EvaluationFunction(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d8c294-3b18-4d22-8790-988090dfc036",
   "metadata": {},
   "source": [
    "### Writing the match functions and the pandas dataframe for storing the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9158ee-f6a0-47f3-ad90-d19c3568b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_agents(agent_a, agent_b, gridsize : tuple, playouts=200):\n",
    "    '''\n",
    "    Function for playout between two different agents on a Connect-Four grid of fixed size.\n",
    "    Agents A and B will play against each other and statistics will be collected and stored in their object instance.\n",
    "    Note that on uneven (even by index since it starts from 0) playouts A will be first to move and on even playouts B will have the first move.\n",
    "    \n",
    "    :param agent_a (): An agent who can play on the specified gridsize.\n",
    "    :param agent_b (): An agent who can play on the specified gridsize.\n",
    "    :param gridsize (tuple): A valid gridsize for the environment and agents, accepts (6,7), (8,9), (10,11), (12,13).\n",
    "    :param playouts (int): The number of games to be played.\n",
    "    '''\n",
    "    \n",
    "    env = ConnectFourEnv(gridsize)\n",
    "    \n",
    "    time_a = []\n",
    "    time_b = []\n",
    "    for i in tqdm(range(playouts),desc='Matches processed:'):\n",
    "        env.reset() #reset environment once\n",
    "        \n",
    "        while not env.terminal:\n",
    "            if (env.turn and (i % 2) == 0) or (not env.turn and (i % 2) == 1):\n",
    "                starttime = datetime.now()\n",
    "                action = agent_a.select_move(env, eval_func=eval_func)\n",
    "                time_a += [(datetime.now()-starttime).microseconds*(10**-6)]\n",
    "                env.step(action)\n",
    "                \n",
    "            elif (not env.turn and (i % 2) == 0) or (env.turn and (i % 2) == 1):\n",
    "                starttime = datetime.now()\n",
    "                action = agent_b.select_move(env, eval_func=eval_func)\n",
    "                time_b += [(datetime.now()-starttime).microseconds*(10**-6)]\n",
    "                env.step(action)\n",
    "        \n",
    "        #after each played match statistics of wins and time are gathered\n",
    "        if (i % 2) == 0:\n",
    "            if env.winner:\n",
    "                agent_a.wins += 1\n",
    "                agent_b.losses += 1\n",
    "                \n",
    "            else:\n",
    "                agent_a.losses += 1\n",
    "                agent_b.wins += 1\n",
    "        else:\n",
    "            if env.winner:\n",
    "                agent_b.wins += 1\n",
    "                agent_a.losses += 1\n",
    "                \n",
    "            else:\n",
    "                agent_b.losses += 1\n",
    "                agent_a.wins += 1\n",
    "    \n",
    "    #after every match was played the time statistics are added\n",
    "    agent_a.average_speed = float(np.mean(time_a))\n",
    "    agent_b.average_speed = float(np.mean(time_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065c5f4-d47c-4753-98aa-2c35a8e19e1c",
   "metadata": {},
   "source": [
    "### Now for each agent we can start to collect data and store it in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1145b6-4f0e-48c1-907e-67f8b446eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['AGENT A','AGENT B', 'GRID', 'A', 'B']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fa19fe-a927-4411-b0f6-d9c94cb6c655",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_for_idx = {0 : 'RandomAgent', 1 : 'AvoidNextLossAgent', 2 : 'MinimaxAgent', 3 : 'ModelAgent', 4 : 'NeuroevolutionAgent'}\n",
    "for gridsize in [(6, 7), (8, 9), (10, 11), (12, 13)]:\n",
    "    for i, agent_a in enumerate([random, lossavoid, minimax, dqn, neuroevo]):\n",
    "        for j, agent_b in enumerate([random, lossavoid, minimax, dqn, neuroevo]):\n",
    "            if i != j and j > i and (not (((i or j) == 4) and gridsize != (6, 7))):\n",
    "                print(f'Putting {name_for_idx[i]} vs {name_for_idx[j]}:')\n",
    "                match_agents(agent_a, agent_b, gridsize)\n",
    "                appendix = pd.DataFrame([[name_for_idx[i],name_for_idx[j],str(gridsize),agent_a.wins,agent_b.wins]],columns=columns)\n",
    "                print(agent_a)\n",
    "                print(agent_b)\n",
    "                print('\\n')\n",
    "                agent_a.reset()\n",
    "                agent_b.reset()\n",
    "                df = df.append(appendix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3204b4a-a266-493e-9902-b47f2f3176f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./performance_data.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e3325-a9b6-4c58-827e-fb1d1af0cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD ANALYSIS FUNCTIONS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c98f26-6ac9-439c-bad4-f01441158649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD VISUALIZATION FUNCTIONS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c7089-b847-465d-aefc-10ada2df9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALL VISUALIZATION AND ANALYSIS FUNCTIONS HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
